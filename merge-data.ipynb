{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = OrderedDict([\n",
    "                          ['eicu', 'eicu/eicu-gossis-data.csv.gz']\n",
    "                        , ['anzics', 'anzics/anzics-gossis-data.csv.gz']\n",
    "                        , ['mimic-iii', 'mimic-iii/mimic-iii-gossis-data.csv.gz']\n",
    "                        #, ['orchestra', 'orchestra/orchestra-gossis-data.csv.gz']\n",
    "                        , ['nicst', 'nicst/nicst-gossis-data.csv.gz']\n",
    "                        #, ['satiq', 'satiq/satiq-gossis-data.csv.gz']\n",
    "    ])\n",
    "\n",
    "df_list = list()\n",
    "for x in datasets:\n",
    "    print('Loading {}...'.format(x), end=' ')\n",
    "    df_list.append( pd.read_csv( datasets[x], header=0, sep=',',\n",
    "                               dtype = {'apache_3j_diagnosis': str, 'apache_2_diagnosis': str}) )\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in the header columns\n",
    "hdr = pd.read_csv('hdr/header.csv',header=None,sep=',')[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop through and print whether the data is present\n",
    "print('Is the data available for the given dataset?')\n",
    "print('A blank indicates it is available. N/A specifies not available.')\n",
    "print('')\n",
    "\n",
    "print('{:30s}'.format('dataset'), end='\\t')\n",
    "for x in datasets:\n",
    "    print('{}'.format(x[0:4]),end='\\t')\n",
    "print('')\n",
    "\n",
    "print_list = ['']*len(df_list)\n",
    "#idxCV = df_mimic['data_source']=='carevue'\n",
    "#df_list = [df_anzics, df_eicu, df_mimic[idxCV], df_mimic[~idxCV], df_orchestra, df_nicst]\n",
    "for c in hdr:\n",
    "    print('{:30s}'.format(c),end=\"\\t\")\n",
    "    \n",
    "    for i, d in enumerate(df_list):\n",
    "        if np.all(d[c].isnull()):\n",
    "            print_list[i] = 'N/A'\n",
    "        else:\n",
    "            print_list[i] = ''\n",
    "        \n",
    "    print('\\t'.join(print_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_source = datasets.keys()\n",
    "\n",
    "# print the same as above to a file - with descriptions and categories\n",
    "# load yaml definitions\n",
    "with open(\"hdr/variable-definitions.yaml\", 'r') as stream:\n",
    "    try:\n",
    "        varlist = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# convert to dataframe\n",
    "df_var = pd.DataFrame.from_dict(varlist, orient='index')\n",
    "df_var['varname'] = df_var.index\n",
    "\n",
    "# we only keep definitions which are in the header file\n",
    "varRemove = list()\n",
    "for i in df_var.index:\n",
    "    if i not in hdr:\n",
    "        varRemove.append(i)\n",
    "df_var.drop(varRemove,axis=0,inplace=True)\n",
    "\n",
    "# specify the order of the categories - data is output in this order\n",
    "category_order = {'identifier': 1,\n",
    "                  'demographic': 2,\n",
    "                  'APACHE covariate': 3,\n",
    "                  'vitals': 4,\n",
    "                  'labs': 5,\n",
    "                  'labs blood gas': 6,\n",
    "                  'APACHE prediction': 10}\n",
    "df_var['category_order'] = df_var['category'].map(category_order)\n",
    "\n",
    "\n",
    "# sort df by the category, then by the variable name\n",
    "df_var.sort_values(['category_order','varname'],inplace=True)\n",
    "\n",
    "with open(\"GOSSIS_VARIABLE_COMPLETION.csv\",\"w\") as fp:\n",
    "    fp.write('variables,category,description,unitofmeasure')\n",
    "    fp.write(','.join(data_source))\n",
    "    fp.write('\\n')\n",
    "    \n",
    "    for c in df_var.index:\n",
    "        for i, d in enumerate(df_list):\n",
    "            if np.all(d[c].isnull()):\n",
    "                print_list[i] = 'N/A'\n",
    "            else:\n",
    "                print_list[i] = ''\n",
    "        fp.write(c + ',')\n",
    "        \n",
    "        # write the category/description of the column\n",
    "        fp.write('\"' + df_var.loc[c, 'category'] + '\",')\n",
    "        fp.write('\"' + df_var.loc[c, 'description'] + '\",')\n",
    "        fp.write('\"' + df_var.loc[c, 'unitofmeasure'] + '\",')\n",
    "        \n",
    "        # write whether data is available\n",
    "        fp.write(','.join(print_list))\n",
    "        fp.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge and spit out the data\n",
    "df = pd.concat(df_list,ignore_index=True)\n",
    "df['data_source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the purposes of data comparison, combine carevue/metavision/both\n",
    "df.loc[np.in1d(df['data_source'],['carevue','metavision','both']),'data_source'] = 'mimic'\n",
    "df['data_source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add in the apache 3 body system\n",
    "ap3_map = pd.read_csv('etc/apache3-to-apache2.csv',sep=',',\n",
    "                     dtype={'apache_3j_diagnosis': str,\n",
    "                            'apache_2_diagnosis': str}\n",
    "                    )\n",
    "\n",
    "ap3_map.drop(['apache_2_diagnosis','ANZICS Added','apache_3j_name'],\n",
    "            axis=1, inplace=True)\n",
    "# create a column containing only the digits before '.'\n",
    "# this is the apache3 diagnosis\n",
    "def get_ap3_code(x):\n",
    "    if 'str' in str(type(x)):\n",
    "        if '.' in x:\n",
    "            return x.split('.')[0]\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['apache3dx'] = df['apache_3j_diagnosis'].map(get_ap3_code)\n",
    "\n",
    "df = df.merge(ap3_map,\n",
    "              how='left', suffixes=('','_ap'),\n",
    "              left_on='apache3dx',\n",
    "              right_on='apache_3j_diagnosis')\n",
    "\n",
    "df.drop(['apache_3j_diagnosis_ap', 'apache3dx','apache_3j_operative'],\n",
    "        axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add in the apache 2 body system\n",
    "ap2_map = pd.read_csv('etc/apache2-definitions.csv',sep=',',\n",
    "                     dtype={'apache_2_diagnosis': str}\n",
    "                    )\n",
    "\n",
    "ap2_map.drop(['apache_2_name','apache_2_coefficient'],\n",
    "            axis=1,inplace=True)\n",
    "ap2_map['apache_2_operative'] = (ap2_map['apache_2_operative'] == 'Post-operative').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(ap2_map,\n",
    "              how='left', suffixes=('','_ap'),\n",
    "              left_on=['apache_2_diagnosis','apache_post_operative'],\n",
    "              right_on=['apache_2_diagnosis', 'apache_2_operative'])\n",
    "df.drop('apache_2_operative',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the three dataframes\n",
    "df.to_csv('gossis-data.csv.gz',index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
