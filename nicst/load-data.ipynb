{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from XLSX, parse it appropriately\n",
    "\n",
    "This script loads the data from a XLSX file and parses the data for concepts required for the GOSSIS project. The script outputs the `nicst-gossis-data.csv` file for later use.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* `sa_dataset_2017417.csv` (for `site` variable which has country)\n",
    "* `SA_data_2017527.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('SA_data_2017527.xlsx',header=0)\n",
    "\n",
    "# convert columns to lower case\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "# hard code the data source as a field\n",
    "df['data_source'] = 'nicst'\n",
    "\n",
    "# load in a previous dataset to get the site information\n",
    "df_old = pd.read_csv('sa_dataset_2017417.csv',header=0,sep=',')\n",
    "\n",
    "# confirm that ID is a good join by checking variables match\n",
    "def iseqna(x, y):\n",
    "    if (x is None) and (y is None):\n",
    "        return True\n",
    "    elif (x is None) or (y is None):\n",
    "        return False\n",
    "    elif np.isnan(x) and np.isnan(y):\n",
    "        return True\n",
    "    elif np.isnan(x) or np.isnan(y):\n",
    "        return False\n",
    "    else:\n",
    "        if x==y:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "df_tmp = df[['id','age',u'sys_bp_highest']].merge(df_old[['id','age','sys_bp_highest']],\n",
    "                                                 how='left', on='id')\n",
    "\n",
    "# coerce datatypes\n",
    "df_tmp['age_x'] = pd.to_numeric(df_tmp['age_x'], errors='coerce')\n",
    "df_tmp['age_y'] = pd.to_numeric(df_tmp['age_y'], errors='coerce')\n",
    "\n",
    "df_tmp['sys_bp_highest_x'] = pd.to_numeric(df_tmp['sys_bp_highest_x'], errors='coerce')\n",
    "df_tmp['sys_bp_highest_y'] = pd.to_numeric(df_tmp['sys_bp_highest_y'], errors='coerce')\n",
    "\n",
    "print('{} of {} have matching age.'.format(\n",
    "        df_tmp.apply(lambda row: iseqna(row['age_x'], row['age_y']), axis=1).sum(),\n",
    "        df.shape[0]))\n",
    "\n",
    "\n",
    "idxGood = df_tmp.apply(lambda row: iseqna(row['sys_bp_highest_x'], row['sys_bp_highest_y']), axis=1) \n",
    "print('{} of {} have matching SBP.'.format(\n",
    "        idxGood.sum(),\n",
    "        df.shape[0]))\n",
    "\n",
    "print('Investigate mis-matched SBP.')\n",
    "print(df_tmp.loc[~idxGood,:])\n",
    "print('Match - but not to machine precision.')\n",
    "print()\n",
    "# yay machine precision\n",
    "\n",
    "# all seems fine, add in site to df\n",
    "df = df.merge(df_old[['id','site']], how='left', on='id', suffixes=('',''))\n",
    "\n",
    "\n",
    "# define operative status in NICST data\n",
    "def get_operative(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return 'Non-operative'\n",
    "    elif 'surgical' in x:\n",
    "        return 'Post-operative'\n",
    "    else:\n",
    "        return 'Non-operative'\n",
    "    \n",
    "df['operative'] = df['admission_type'].map(get_operative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Exclusions which already existed during study design: age > 18.')\n",
    "print('Initial cohort: {} ICU stays.'.format(df.shape[0]))\n",
    "\n",
    "# remove missing outcomes\n",
    "idxRem = df['mortality'].isnull()\n",
    "print('\\t{} ({:2.2f}%) - missing outcome.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = ~idxRem\n",
    "\n",
    "# remove readmissions\n",
    "idxRem = np.zeros(df.shape[0], dtype=bool)\n",
    "print('\\t{} ({:2.2f}%) - readmissions.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "# missing ap-ii pred\n",
    "idxRem = ~(df['a_score']>0)\n",
    "print('\\t{} ({:2.2f}%) - patients missing apache prediction.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "# missing heart rate\n",
    "idxRem = (  (df['heart_rate_lowest'].isnull()) | (df['heart_rate_highest'].isnull())  )\n",
    "print('\\t{} ({:2.2f}%) - missing data.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "df = df.loc[idxKeep, :]\n",
    "\n",
    "print('Final cohort: {} ICU stays.'.format(df.shape[0]))\n",
    "\n",
    "np.sum(df['mortality'].isnull())\n",
    "print('Final cohort size: {}'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix some data\n",
    "\n",
    "Things we can fix:\n",
    "\n",
    "* `height` of \"NA###\" are weights accidentally placed next to an NA height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix 3 missing weights\n",
    "idxFix = ['NA' in str(x) for x in df['height']]\n",
    "df.loc[idxFix,'weight'] = [x.replace('NA','').strip(' ') for x in df.loc[idxFix,'height']]\n",
    "df.loc[idxFix,'height'] = 'na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add ANZICS diagnosis codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add in ANZICS dx code in two joins\n",
    "dx = pd.read_csv('anzics-to-nicst-apache2-map.csv',header=0,sep=',')\n",
    "\n",
    "# join 1: diagnoses where operative/non-operative doesn't matter\n",
    "id_keep = dx.dropna().groupby('nicst_id')['nicst_name'].count()\n",
    "id_keep = id_keep.index[id_keep>1].values\n",
    "idx = ~np.in1d(dx['nicst_id'], id_keep)\n",
    "dx1 = dx.loc[idx, :].dropna()\n",
    "\n",
    "df = df.merge(dx1, suffixes=('',''),\n",
    "              how='left',\n",
    "              left_on='apachecode',\n",
    "             right_on='nicst_id')\n",
    "\n",
    "# join 2: diagnoses where the NICST ID is the same for operative/non-operative dx\n",
    "# (this is because the coefficients are the same)\n",
    "# for these, we use the operative status of the patient to complete the join\n",
    "idx = np.in1d(dx['nicst_id'], id_keep)\n",
    "dx2 = dx.loc[idx, :].dropna()\n",
    "df = df.merge(dx2, suffixes=('','_2'),\n",
    "              how='left',\n",
    "              left_on=['apachecode','operative'],\n",
    "             right_on=['nicst_id','anzics_operative'])\n",
    "\n",
    "# combine together into a single column\n",
    "idx = df['anzics_id'].isnull()\n",
    "col_list = dx2.columns\n",
    "for c in col_list:\n",
    "    if c + '_2' in df:\n",
    "        df.loc[idx, c] = df.loc[idx, c + '_2']\n",
    "        df.drop(c + '_2', axis=1, inplace=True)\n",
    "\n",
    "# sanity check:\n",
    "#  df.groupby(['anzics_id','anzics_name','anzics_operative'])[['nicst_id']].agg([len, min, max])\n",
    "# this shows that the min/max nicst_id is always the same, therefore the value is always the same\n",
    "\n",
    "# ensure we have all data\n",
    "print('{} of {} patients have an APACHE II code.'.format((~df['apachecode'].isnull()).sum(),\n",
    "                                                         df.shape[0]))\n",
    "\n",
    "print('{} of {} patients have a mapped ANZICS diagnosis.'.format((~df['anzics_id'].isnull()).sum(),\n",
    "                                                         df.shape[0]))\n",
    "# convert to string\n",
    "df['anzics_id'].fillna(0, inplace=True)\n",
    "df['anzics_id'] = df['anzics_id'].map(int).map(str).map(lambda x: None if x == '0' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the mapping from NICST variables to GOSSIS variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define functions/dictionaries necessary for mapping any coded data into a general format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionaries\n",
    "dict_site = {\n",
    "    3: 'India', # number of obs: 2283\n",
    "    4: 'Sri Lanka', # 817\n",
    "    1: 'Bangladesh', # 430\n",
    "    2: 'Nepal' # 325\n",
    "}\n",
    "\n",
    "dict_gender = {\n",
    "    'Male': 'M',\n",
    "    'Female': 'F',\n",
    "    '.': None,\n",
    "    np.nan: None,\n",
    "    'female': 'F',\n",
    "    'male': 'M'}\n",
    "\n",
    "def fixWeight(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            return float(x.replace('kg','').strip(' '))\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def fixHeight(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            # convert to cm\n",
    "            z = x.lower()\n",
    "            if 'inch' in z:\n",
    "                z = z.replace('inch','').strip(' ')\n",
    "                z = float(z)*2.54\n",
    "                return z\n",
    "            elif 'cm' in z:\n",
    "                z = z.replace('cm','').strip(' ')\n",
    "                return float(z)\n",
    "            else:\n",
    "                z = z.replace('na','').strip(' ')\n",
    "                z = float(z)\n",
    "                return z\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def fixAge(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            # convert to cm\n",
    "            z = x.lower()\n",
    "            if 'months' in z:\n",
    "                z = z.replace('months','').strip(' ')\n",
    "                z = float(z)/12.0\n",
    "                return z\n",
    "            elif 'yrs' in z:\n",
    "                z = z.replace('yrs','').strip(' ')\n",
    "                return float(z)\n",
    "            elif 'years' in z:\n",
    "                z = z.replace('years','').strip(' ')\n",
    "                return float(z)\n",
    "            else:\n",
    "                z = z.replace('na','').strip(' ')\n",
    "                z = float(z)\n",
    "                if z > 150:\n",
    "                    # bad data\n",
    "                    return np.nan\n",
    "                else:\n",
    "                    return z\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def ensurePercentage(x):\n",
    "    if x > 100:\n",
    "        return np.nan\n",
    "    elif x < 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "dict_operative = {\n",
    "    'Post-operative': 1,\n",
    "    'Non-operative': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a dictionary which maps from the GOSISS variable name (the key) to the NICST data (the value) - where the latter is either:\n",
    "* a direct copy-paste of the data (in which case it the value is the string name of the column in the original dataframe)\n",
    "* a function of the data (usually involves calling the dictionary to map from coded values to the general form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encounter id is a concatenation of of:\n",
    "#   - siteid, patientid, admepisode (incrementing integer for each ICU stay)\n",
    "encFcn = lambda x: 'nicst_' + x['id'].astype(str)\n",
    "\n",
    "field_map = OrderedDict([\n",
    "['data_source', 'data_source']\n",
    ", ['encounter_id', encFcn]\n",
    ", ['patient_id', encFcn]\n",
    ", ['country', lambda x: x['site'].map(dict_site)]\n",
    ", ['hospital_id', None]\n",
    ", ['teaching_hospital', None]\n",
    ", ['hospital_bed_size', None]\n",
    ", ['hospital_type', None]\n",
    ", ['icu_id', 'icu_id']\n",
    ", ['icu_type', None]\n",
    ", ['icu_stay_type', None]\n",
    ", ['age', fixAge]\n",
    ", ['gender', lambda x: x['sex'].map(dict_gender)]\n",
    ", ['weight', lambda x: x['weight'].map(fixWeight)]\n",
    ", ['height', lambda x: x['height'].map(fixHeight)]\n",
    ", ['bmi', lambda x: x['weight'].map(fixWeight) / ( (x['height'].map(fixHeight)/100) ** 2)]\n",
    ", ['ethnicity', None]\n",
    ", ['pregnant', None]\n",
    ", ['smoking_status', None]\n",
    ", ['hospital_admit_source', None]\n",
    ", ['hospital_disch_location', None]\n",
    ", ['hospital_los_days', None]\n",
    ", ['hospital_death', None]\n",
    ", ['icu_admit_source', None]\n",
    ", ['icu_admit_type', None]\n",
    ", ['icu_disch_location', None]\n",
    ", ['pre_icu_los_days', None]\n",
    ", ['icu_los_days', 'lengthofstay']\n",
    ", ['icu_death', 'mortality']\n",
    ", ['elective_surgery', None]\n",
    ", ['readmission_status', None]\n",
    "# === VITALS === #\n",
    ", ['d1_heartrate_min', 'heart_rate_lowest']\n",
    ", ['d1_heartrate_max', 'heart_rate_highest']\n",
    ", ['d1_resprate_min', 'resp_rate_lowest']\n",
    ", ['d1_resprate_max', 'resp_rate_highest']\n",
    ", ['d1_spo2_min', lambda x: x['saturate_lowest'].map(ensurePercentage)]\n",
    ", ['d1_spo2_max', lambda x: x['saturate_highest'].map(ensurePercentage)]\n",
    ", ['d1_temp_min', 'temp_lowest']\n",
    ", ['d1_temp_max', 'temp_highest']\n",
    ", ['d1_sysbp_invasive_min', None]\n",
    ", ['d1_sysbp_invasive_max', None]\n",
    ", ['d1_diasbp_invasive_min', None]\n",
    ", ['d1_diasbp_invasive_max', None]\n",
    ", ['d1_mbp_invasive_min', None]\n",
    ", ['d1_mbp_invasive_max', None]\n",
    ", ['d1_sysbp_noninvasive_min', None]\n",
    ", ['d1_sysbp_noninvasive_max', None]\n",
    ", ['d1_diasbp_noninvasive_min', None]\n",
    ", ['d1_diasbp_noninvasive_max', None]\n",
    ", ['d1_mbp_noninvasive_min', None]\n",
    ", ['d1_mbp_noninvasive_max', None]\n",
    ", ['d1_sysbp_min', 'sys_bp_lowest']\n",
    ", ['d1_sysbp_max', 'sys_bp_highest']\n",
    ", ['d1_diasbp_min', None]\n",
    ", ['d1_diasbp_max', None]\n",
    ", ['d1_mbp_min', 'map_lowest']\n",
    ", ['d1_mbp_max', 'map_highest']\n",
    ", ['d1_pasys_invasive_min', None]\n",
    ", ['d1_pasys_invasive_max', None]\n",
    ", ['d1_padias_invasive_min', None]\n",
    ", ['d1_padias_invasive_max', None]\n",
    ", ['d1_pamean_invasive_min', None]\n",
    ", ['d1_pamean_invasive_max', None]\n",
    "# hourly\n",
    ", ['h1_heartrate_min', None]\n",
    ", ['h1_heartrate_max', None]\n",
    ", ['h1_resprate_min', None]\n",
    ", ['h1_resprate_max', None]\n",
    ", ['h1_spo2_min', None]\n",
    ", ['h1_spo2_max', None]\n",
    ", ['h1_temp_min', None]\n",
    ", ['h1_temp_max', None]\n",
    ", ['h1_sysbp_invasive_min', None]\n",
    ", ['h1_sysbp_invasive_max', None]\n",
    ", ['h1_diasbp_invasive_min', None]\n",
    ", ['h1_diasbp_invasive_max', None]\n",
    ", ['h1_mbp_invasive_min', None]\n",
    ", ['h1_mbp_invasive_max', None]\n",
    ", ['h1_sysbp_noninvasive_min', None]\n",
    ", ['h1_sysbp_noninvasive_max', None]\n",
    ", ['h1_diasbp_noninvasive_min', None]\n",
    ", ['h1_diasbp_noninvasive_max', None]\n",
    ", ['h1_mbp_noninvasive_min', None]\n",
    ", ['h1_mbp_noninvasive_max', None]\n",
    ", ['h1_sysbp_min', None]\n",
    ", ['h1_sysbp_max', None]\n",
    ", ['h1_diasbp_min', None]\n",
    ", ['h1_diasbp_max', None]\n",
    ", ['h1_mbp_min', None]\n",
    ", ['h1_mbp_max', None]\n",
    ", ['h1_pasys_invasive_min', None]\n",
    ", ['h1_pasys_invasive_max', None]\n",
    ", ['h1_padias_invasive_min', None]\n",
    ", ['h1_padias_invasive_max', None]\n",
    ", ['h1_pamean_invasive_min', None]\n",
    ", ['h1_pamean_invasive_max', None]\n",
    "# === LABS/BLOOD GASES === #\n",
    ", ['d1_albumin_min', None]\n",
    ", ['d1_albumin_max', None]\n",
    ", ['d1_bilirubin_min', None]\n",
    ", ['d1_bilirubin_max', None]\n",
    ", ['d1_bun_min', 'bun_lowest']\n",
    ", ['d1_bun_max', 'bun_highest']\n",
    ", ['d1_calcium_min', None]\n",
    ", ['d1_calcium_max', None]\n",
    ", ['d1_creatinine_min', 'creatinine_lowest'] # mg/dL\n",
    ", ['d1_creatinine_max', 'creatinine_highest'] # mg/dL\n",
    ", ['d1_glucose_min', None] \n",
    ", ['d1_glucose_max', None] \n",
    ", ['d1_inr_min', None]\n",
    ", ['d1_inr_max', None]\n",
    ", ['d1_hco3_min', None]\n",
    ", ['d1_hco3_max', None]\n",
    ", ['d1_hematocrit_min', lambda x: x['pcv_lowest'].map(ensurePercentage)]\n",
    ", ['d1_hematocrit_max', lambda x: x['pcv_highest'].map(ensurePercentage)]\n",
    ", ['d1_hemaglobin_min', 'hb_lowest'] # g/dL\n",
    ", ['d1_hemaglobin_max', 'hb_highest'] # g/dL\n",
    ", ['d1_lactate_min', None]\n",
    ", ['d1_lactate_max', None]\n",
    ", ['d1_platelets_min', None]\n",
    ", ['d1_platelets_max', None]\n",
    ", ['d1_potassium_min', 'pottasium_lowest'] # mmol/L == mEq/L\n",
    ", ['d1_potassium_max', 'pottasium_highest'] # mmol/L == mEq/L\n",
    ", ['d1_sodium_min', 'sodium_lowest'] # mmol/L == mEq/L\n",
    ", ['d1_sodium_max', 'sodium_highest'] # mmol/L == mEq/L\n",
    ", ['d1_wbc_min', 'wbc_lowest']\n",
    ", ['d1_wbc_max', 'wbc_highest']\n",
    ", ['d1_arterial_ph_min', 'ph_lowest']\n",
    ", ['d1_arterial_ph_max', 'ph_highest']\n",
    ", ['d1_arterial_po2_min', 'pao2_lowest']\n",
    ", ['d1_arterial_po2_max', 'pao2_highest']\n",
    ", ['d1_arterial_pco2_min', None]\n",
    ", ['d1_arterial_pco2_max', None]\n",
    ", ['d1_pao2fio2ratio_min', None]\n",
    ", ['d1_pao2fio2ratio_max', None]\n",
    "# hourly\n",
    ", ['h1_albumin_min', None]\n",
    ", ['h1_albumin_max', None]\n",
    ", ['h1_bilirubin_min', None]\n",
    ", ['h1_bilirubin_max', None]\n",
    ", ['h1_bun_min', None]\n",
    ", ['h1_bun_max', None]\n",
    ", ['h1_calcium_min', None]\n",
    ", ['h1_calcium_max', None]\n",
    ", ['h1_creatinine_min', None]\n",
    ", ['h1_creatinine_max', None]\n",
    ", ['h1_glucose_min', None]\n",
    ", ['h1_glucose_max', None]\n",
    ", ['h1_inr_min', None]\n",
    ", ['h1_inr_max', None]\n",
    ", ['h1_hco3_min', None]\n",
    ", ['h1_hco3_max', None]\n",
    ", ['h1_hematocrit_min', None]\n",
    ", ['h1_hematocrit_max', None]\n",
    ", ['h1_hemaglobin_min', None]\n",
    ", ['h1_hemaglobin_max', None]\n",
    ", ['h1_lactate_min', None]\n",
    ", ['h1_lactate_max', None]\n",
    ", ['h1_platelets_min', None]\n",
    ", ['h1_platelets_max', None]\n",
    ", ['h1_potassium_min', None]\n",
    ", ['h1_potassium_max', None]\n",
    ", ['h1_sodium_min', None]\n",
    ", ['h1_sodium_max', None]\n",
    ", ['h1_wbc_min', None]\n",
    ", ['h1_wbc_max', None]\n",
    ", ['h1_arterial_ph_min', None]\n",
    ", ['h1_arterial_ph_max', None]\n",
    ", ['h1_arterial_po2_min', None]\n",
    ", ['h1_arterial_po2_max', None]\n",
    ", ['h1_arterial_pco2_min', None]\n",
    ", ['h1_arterial_pco2_max', None]\n",
    ", ['h1_pao2fio2ratio_min', None]\n",
    ", ['h1_pao2fio2ratio_max', None]\n",
    "# === COMORBIDITIES === #\n",
    ", ['diabetes_mellitus', 'diabetes']\n",
    "#, [None, 'diabetes_type']\n",
    ", ['aids', 'aids']\n",
    "#, [None, 'tuberculosis']\n",
    "#, [None, 'past_tb']\n",
    "#, [None, 'hepatitis_b']\n",
    "#, [None, 'other_chronic']\n",
    "#, [None, 'other_chronic_specify']\n",
    "#, [None, 'antidiabetic']\n",
    "#, [None, 'antidiabetic_specify']\n",
    "#, [None, 'stayhr']\n",
    "\n",
    "# === APACHE III VARIABLES === #\n",
    ", ['albumin_apache', None]\n",
    ", ['bilirubin_apache', None]\n",
    ", ['creatinine_apache', None]\n",
    ", ['glucose_apache', None]\n",
    ", ['hematocrit_apache', None]\n",
    ", ['heart_rate_apache', None]\n",
    ", ['map_apache', None]\n",
    ", ['sodium_apache', None]\n",
    "# aps iii oxygenation blood gas\n",
    ", ['fio2_apache', None]\n",
    ", ['paco2_apache', None]\n",
    ", ['pao2_apache', None]\n",
    "# aps iii acid-base components\n",
    ", ['ph_apache', None]\n",
    ", ['paco2_for_ph_apache', None]\n",
    ", ['resprate_apache', None]\n",
    ", ['temp_apache', None]\n",
    ", ['bun_apache', None]\n",
    ", ['urineoutput_apache', None]\n",
    ", ['wbc_apache', None]\n",
    ", ['gcs_eyes_apache', None]\n",
    ", ['gcs_motor_apache', None]\n",
    ", ['gcs_verbal_apache', None]\n",
    ", ['gcs_apache', 'gcs_lowest']\n",
    ", ['gcs_unable_apache', None]\n",
    ", ['arf_apache', None]\n",
    ", ['ventilated_apache', 'mechanical_first_24h']\n",
    "# === TREATMENTS === #\n",
    "#, [None, 'vasoactive_first_h']\n",
    "#, [None, 'antibiotic_drugs']\n",
    "# === OUTPUT OF SCORING SYSTEMS === #\n",
    "#, [None, 'a_score'] # probably apache ii\n",
    "#, [None, 'prob'] # probably apache ii\n",
    ", ['apsiii', None]\n",
    ", ['apache_post_operative', lambda x: x['operative'].map(dict_operative)]\n",
    ", ['apache_2_diagnosis', 'anzics_id']\n",
    ", ['apache_3j_diagnosis', None]\n",
    ", ['apache_3j_score', None]\n",
    ", ['apache_3j_hospital_death_prob', None]\n",
    ", ['apache_4a_icu_death_prob', None]\n",
    ", ['apache_4a_hospital_death_prob', None]\n",
    "])\n",
    "        \n",
    "# === OTHER UNUSED VARIABLES === #\n",
    "#, [None, 'apachecode']\n",
    "#, [None, 'diagnosis']\n",
    "#, [None, 'temp_onadm'],\n",
    "#, [None, 'map_onadm']\n",
    "#, [None, 'heart_rate_onadm']\n",
    "#, [None, 'resp_rate_onadm']\n",
    "#, [None, 'pao2_onadm']\n",
    "#, [None, 'ph_onadm'],\n",
    "#, [None, 'sodium_onadm'],\n",
    "#, [None, 'pottasium_onadm'],\n",
    "#, [None, 'creatinine_onadm'],\n",
    "#, [None, 'pcv_onadm']\n",
    "#, [None, 'wbc_onadm']\n",
    "#, [None, 'gcs_highest']\n",
    "#, [None, 'gcs_onadm']\n",
    "#, [None, 'hb_onadm'],\n",
    "#, [None, 'sys_bp_onadm'],\n",
    "#, [None, 'saturate_onadm'],\n",
    "#, [None, 'fio2_highest']\n",
    "#, [None, 'fio2_lowest']\n",
    "#, [None, 'fio2_onadm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr = pd.read_csv('../hdr/header.csv',header=None,sep=',')[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for c in hdr:\n",
    "    # did not find a mapping for the given variable\n",
    "    if c not in field_map:\n",
    "        print('WARNING: {} not found in field mapping for NICST data!'.format(c))\n",
    "        df_new[c] = None\n",
    "    # there is a mapping, but it indicates that we don't have any data\n",
    "    elif field_map[c] is None:\n",
    "        # plug in missing data into final dataframe\n",
    "        #print('WARNING: {} not available in NICST data!'.format(c))\n",
    "        df_new[c] = None\n",
    "    # there is a mapping, and the anzics definition matches the GOSISS definition\n",
    "    elif type(field_map[c]) == str:\n",
    "        # check the mapping refers to a column available in data\n",
    "        if field_map[c].lower() in df.columns.values:\n",
    "            # data exists, copy it over\n",
    "            df_new[c] = df[field_map[c]]\n",
    "        else:\n",
    "            print('WARNING: {} equivalent not found in NICST data! (Looked for \"{}\".)'.format(c, field_map[c].lower()))\n",
    "    # there is a mapping, and it's a function (usually a dictionary)\n",
    "    else:\n",
    "        # call the mapping\n",
    "        df_new[c] = field_map[c](df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Output the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new.to_csv('nicst-gossis-data.csv.gz',index=False,sep=',',compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
