{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from XLSX, parse it appropriately\n",
    "\n",
    "This script loads the data from a XLSX file and parses the data for concepts required for the GOSISS project. The script outputs the `nicst-gosiss-data.csv` file for later use.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* `SA_dataset_2017417.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sa_dataset_2017417.csv',header=0,sep=',')\n",
    "#df = pd.read_csv('anzics_mini.csv',header=0,sep=',')\n",
    "\n",
    "# convert columns to lower case\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "# hard code the data source as a field\n",
    "df['data_source'] = 'nicst'\n",
    "df['country'] = 'South Asia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclusions which already existed during study design: age > 18.\n",
      "Initial cohort: 3855 ICU stays.\n",
      "\t234 (6.07%) - missing outcome.\n",
      "\t0 (0.00%) - readmissions.\n",
      "\t0 (0.00%) - patients missing apache prediction.\n",
      "\t264 (6.85%) - missing data.\n",
      "Final cohort: 3419 ICU stays.\n",
      "Final cohort size: 3419\n"
     ]
    }
   ],
   "source": [
    "print('Exclusions which already existed during study design: age > 18.')\n",
    "print('Initial cohort: {} ICU stays.'.format(df.shape[0]))\n",
    "\n",
    "# remove missing outcomes\n",
    "idxRem = df['mortality'].isnull()\n",
    "print('\\t{} ({:2.2f}%) - missing outcome.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = ~idxRem\n",
    "\n",
    "# remove readmissions\n",
    "idxRem = np.zeros(df.shape[0], dtype=bool)\n",
    "print('\\t{} ({:2.2f}%) - readmissions.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "# missing ap-ii pred\n",
    "idxRem = ~(df['a_score']>0)\n",
    "print('\\t{} ({:2.2f}%) - patients missing apache prediction.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "# missing heart rate\n",
    "idxRem = (  (df['heart_rate_lowest'].isnull()) | (df['heart_rate_highest'].isnull())  )\n",
    "print('\\t{} ({:2.2f}%) - missing data.'.format(np.sum(idxRem), np.sum(idxRem)*100.0/df.shape[0]))\n",
    "idxKeep = (~idxRem) & idxKeep\n",
    "\n",
    "df = df.loc[idxKeep, :]\n",
    "\n",
    "print('Final cohort: {} ICU stays.'.format(df.shape[0]))\n",
    "\n",
    "np.sum(df['mortality'].isnull())\n",
    "print('Final cohort size: {}'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix some data\n",
    "\n",
    "Things we can fix:\n",
    "\n",
    "* `height` of \"NA###\" are weights accidentally placed next to an NA height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix 3 missing weights\n",
    "idxFix = ['NA' in str(x) for x in df['height']]\n",
    "df.loc[idxFix,'weight'] = [x.replace('NA','').strip(' ') for x in df.loc[idxFix,'height']]\n",
    "df.loc[idxFix,'height'] = 'na'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the mapping from NICST variables to GOSSIS variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define functions/dictionaries necessary for mapping any coded data into a general format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionaries\n",
    "dict_site = {\n",
    "    3: 'India', # number of obs: 2283\n",
    "    4: 'Sri Lanka', # 817\n",
    "    1: 'Bangladesh', # 430\n",
    "    2: 'Nepal' # 325\n",
    "}\n",
    "\n",
    "dict_gender = {\n",
    "    'Male': 'M',\n",
    "    'Female': 'F',\n",
    "    '.': None,\n",
    "    np.nan: None,\n",
    "    'female': 'F',\n",
    "    'male': 'M'}\n",
    "\n",
    "def fixWeight(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            return float(x.replace('kg','').strip(' '))\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def fixHeight(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            # convert to cm\n",
    "            z = x.lower()\n",
    "            if 'inch' in z:\n",
    "                z = z.replace('inch','').strip(' ')\n",
    "                z = float(z)*2.54\n",
    "                return z\n",
    "            elif 'cm' in z:\n",
    "                z = z.replace('cm','').strip(' ')\n",
    "                return float(z)\n",
    "            else:\n",
    "                z = z.replace('na','').strip(' ')\n",
    "                z = float(z)\n",
    "                return z\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def fixAge(x):\n",
    "    if 'float' in str(type(x)):\n",
    "        return x\n",
    "    elif 'str' in str(type(x)):\n",
    "        try:\n",
    "            # convert to cm\n",
    "            z = x.lower()\n",
    "            if 'months' in z:\n",
    "                z = z.replace('months','').strip(' ')\n",
    "                z = float(z)/12.0\n",
    "                return z\n",
    "            elif 'yrs' in z:\n",
    "                z = z.replace('yrs','').strip(' ')\n",
    "                return float(z)\n",
    "            elif 'years' in z:\n",
    "                z = z.replace('years','').strip(' ')\n",
    "                return float(z)\n",
    "            else:\n",
    "                z = z.replace('na','').strip(' ')\n",
    "                z = float(z)\n",
    "                if z > 150:\n",
    "                    # bad data\n",
    "                    return np.nan\n",
    "                else:\n",
    "                    return z\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def ensurePercentage(x):\n",
    "    if x > 100:\n",
    "        return np.nan\n",
    "    elif x < 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a dictionary which maps from the GOSISS variable name (the key) to the NICST data (the value) - where the latter is either:\n",
    "* a direct copy-paste of the data (in which case it the value is the string name of the column in the ANZICS data)\n",
    "* a function of the data (usually involves calling the dictionary to map from coded values to the general form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encounter id is a concatenation of of:\n",
    "#   - siteid, patientid, admepisode (incrementing integer for each ICU stay)\n",
    "encFcn = lambda x: 'nicst_' + x['id'].astype(str)\n",
    "\n",
    "field_map = OrderedDict([\n",
    "['data_source', 'data_source']\n",
    ", ['encounter_id', encFcn]\n",
    ", ['patient_id', encFcn]\n",
    ", ['country', lambda x: x['site'].map(dict_site)]\n",
    ", ['hospital_id', None]\n",
    ", ['teaching_hospital', None]\n",
    ", ['hospital_bed_size', None]\n",
    ", ['hospital_type', None]\n",
    ", ['icu_id', None]\n",
    ", ['icu_type', None]\n",
    ", ['icu_stay_type', None]\n",
    ", ['age', fixAge]\n",
    ", ['gender', lambda x: x['sex'].map(dict_gender)]\n",
    ", ['weight', lambda x: x['weight'].map(fixWeight)]\n",
    ", ['height', lambda x: x['height'].map(fixHeight)]\n",
    ", ['bmi', lambda x: x['weight'].map(fixWeight) / ( (x['height'].map(fixHeight)/100) ** 2)]\n",
    ", ['ethnicity', None]\n",
    ", ['pregnant', None]\n",
    ", ['smoking_status', None]\n",
    ", ['hospital_admit_source', None]\n",
    ", ['hospital_disch_location', None]\n",
    ", ['hospital_los_days', None]\n",
    ", ['hospital_death', None]\n",
    ", ['icu_admit_source', None]\n",
    ", ['icu_admit_type', None]\n",
    ", ['icu_disch_location', None]\n",
    ", ['pre_icu_los_days', None]\n",
    ", ['icu_los_days', 'lengthofstay']\n",
    ", ['icu_death', 'mortality']\n",
    ", ['elective_surgery', None]\n",
    ", ['readmission_status', None]\n",
    "# === VITALS === #\n",
    ", ['d1_heartrate_min', 'heart_rate_lowest']\n",
    ", ['d1_heartrate_max', 'heart_rate_highest']\n",
    ", ['d1_resprate_min', 'resp_rate_lowest']\n",
    ", ['d1_resprate_max', 'resp_rate_highest']\n",
    ", ['d1_spo2_min', lambda x: x['saturate_lowest'].map(ensurePercentage)]\n",
    ", ['d1_spo2_max', lambda x: x['saturate_highest'].map(ensurePercentage)]\n",
    ", ['d1_temp_min', 'temp_lowest']\n",
    ", ['d1_temp_max', 'temp_highest']\n",
    ", ['d1_sysbp_invasive_min', None]\n",
    ", ['d1_sysbp_invasive_max', None]\n",
    ", ['d1_diasbp_invasive_min', None]\n",
    ", ['d1_diasbp_invasive_max', None]\n",
    ", ['d1_mbp_invasive_min', None]\n",
    ", ['d1_mbp_invasive_max', None]\n",
    ", ['d1_sysbp_noninvasive_min', None]\n",
    ", ['d1_sysbp_noninvasive_max', None]\n",
    ", ['d1_diasbp_noninvasive_min', None]\n",
    ", ['d1_diasbp_noninvasive_max', None]\n",
    ", ['d1_mbp_noninvasive_min', None]\n",
    ", ['d1_mbp_noninvasive_max', None]\n",
    ", ['d1_sysbp_min', 'sys_bp_lowest']\n",
    ", ['d1_sysbp_max', 'sys_bp_highest']\n",
    ", ['d1_diasbp_min', None]\n",
    ", ['d1_diasbp_max', None]\n",
    ", ['d1_mbp_min', 'map_lowest']\n",
    ", ['d1_mbp_max', 'map_highest']\n",
    ", ['d1_pasys_invasive_min', None]\n",
    ", ['d1_pasys_invasive_max', None]\n",
    ", ['d1_padias_invasive_min', None]\n",
    ", ['d1_padias_invasive_max', None]\n",
    ", ['d1_pamean_invasive_min', None]\n",
    ", ['d1_pamean_invasive_max', None]\n",
    "# hourly\n",
    ", ['h1_heartrate_min', None]\n",
    ", ['h1_heartrate_max', None]\n",
    ", ['h1_resprate_min', None]\n",
    ", ['h1_resprate_max', None]\n",
    ", ['h1_spo2_min', None]\n",
    ", ['h1_spo2_max', None]\n",
    ", ['h1_temp_min', None]\n",
    ", ['h1_temp_max', None]\n",
    ", ['h1_sysbp_invasive_min', None]\n",
    ", ['h1_sysbp_invasive_max', None]\n",
    ", ['h1_diasbp_invasive_min', None]\n",
    ", ['h1_diasbp_invasive_max', None]\n",
    ", ['h1_mbp_invasive_min', None]\n",
    ", ['h1_mbp_invasive_max', None]\n",
    ", ['h1_sysbp_noninvasive_min', None]\n",
    ", ['h1_sysbp_noninvasive_max', None]\n",
    ", ['h1_diasbp_noninvasive_min', None]\n",
    ", ['h1_diasbp_noninvasive_max', None]\n",
    ", ['h1_mbp_noninvasive_min', None]\n",
    ", ['h1_mbp_noninvasive_max', None]\n",
    ", ['h1_sysbp_min', None]\n",
    ", ['h1_sysbp_max', None]\n",
    ", ['h1_diasbp_min', None]\n",
    ", ['h1_diasbp_max', None]\n",
    ", ['h1_mbp_min', None]\n",
    ", ['h1_mbp_max', None]\n",
    ", ['h1_pasys_invasive_min', None]\n",
    ", ['h1_pasys_invasive_max', None]\n",
    ", ['h1_padias_invasive_min', None]\n",
    ", ['h1_padias_invasive_max', None]\n",
    ", ['h1_pamean_invasive_min', None]\n",
    ", ['h1_pamean_invasive_max', None]\n",
    "# === LABS/BLOOD GASES === #\n",
    ", ['d1_albumin_min', None]\n",
    ", ['d1_albumin_max', None]\n",
    ", ['d1_bilirubin_min', None]\n",
    ", ['d1_bilirubin_max', None]\n",
    ", ['d1_bun_min', 'bun_lowest']\n",
    ", ['d1_bun_max', 'bun_highest']\n",
    ", ['d1_calcium_min', None]\n",
    ", ['d1_calcium_max', None]\n",
    ", ['d1_creatinine_min', 'creatinine_lowest'] # mg/dL\n",
    ", ['d1_creatinine_max', 'creatinine_highest'] # mg/dL\n",
    ", ['d1_glucose_min', None] \n",
    ", ['d1_glucose_max', None] \n",
    ", ['d1_inr_min', None]\n",
    ", ['d1_inr_max', None]\n",
    ", ['d1_hco3_min', None]\n",
    ", ['d1_hco3_max', None]\n",
    ", ['d1_hematocrit_min', lambda x: x['pcv_lowest'].map(ensurePercentage)]\n",
    ", ['d1_hematocrit_max', lambda x: x['pcv_highest'].map(ensurePercentage)]\n",
    ", ['d1_hemaglobin_min', 'hb_lowest'] # g/dL\n",
    ", ['d1_hemaglobin_max', 'hb_highest'] # g/dL\n",
    ", ['d1_lactate_min', None]\n",
    ", ['d1_lactate_max', None]\n",
    ", ['d1_platelets_min', None]\n",
    ", ['d1_platelets_max', None]\n",
    ", ['d1_potassium_min', 'pottasium_lowest'] # mmol/L == mEq/L\n",
    ", ['d1_potassium_max', 'pottasium_highest'] # mmol/L == mEq/L\n",
    ", ['d1_sodium_min', 'sodium_lowest'] # mmol/L == mEq/L\n",
    ", ['d1_sodium_max', 'sodium_highest'] # mmol/L == mEq/L\n",
    ", ['d1_wbc_min', 'wbc_lowest']\n",
    ", ['d1_wbc_max', 'wbc_highest']\n",
    ", ['d1_arterial_ph_min', 'ph_lowest']\n",
    ", ['d1_arterial_ph_max', 'ph_highest']\n",
    ", ['d1_arterial_po2_min', 'pao2_lowest']\n",
    ", ['d1_arterial_po2_max', 'pao2_highest']\n",
    ", ['d1_arterial_pco2_min', None]\n",
    ", ['d1_arterial_pco2_max', None]\n",
    ", ['d1_pao2fio2ratio_min', None]\n",
    ", ['d1_pao2fio2ratio_max', None]\n",
    "# hourly\n",
    ", ['h1_albumin_min', None]\n",
    ", ['h1_albumin_max', None]\n",
    ", ['h1_bilirubin_min', None]\n",
    ", ['h1_bilirubin_max', None]\n",
    ", ['h1_bun_min', None]\n",
    ", ['h1_bun_max', None]\n",
    ", ['h1_calcium_min', None]\n",
    ", ['h1_calcium_max', None]\n",
    ", ['h1_creatinine_min', None]\n",
    ", ['h1_creatinine_max', None]\n",
    ", ['h1_glucose_min', None]\n",
    ", ['h1_glucose_max', None]\n",
    ", ['h1_inr_min', None]\n",
    ", ['h1_inr_max', None]\n",
    ", ['h1_hco3_min', None]\n",
    ", ['h1_hco3_max', None]\n",
    ", ['h1_hematocrit_min', None]\n",
    ", ['h1_hematocrit_max', None]\n",
    ", ['h1_hemaglobin_min', None]\n",
    ", ['h1_hemaglobin_max', None]\n",
    ", ['h1_lactate_min', None]\n",
    ", ['h1_lactate_max', None]\n",
    ", ['h1_platelets_min', None]\n",
    ", ['h1_platelets_max', None]\n",
    ", ['h1_potassium_min', None]\n",
    ", ['h1_potassium_max', None]\n",
    ", ['h1_sodium_min', None]\n",
    ", ['h1_sodium_max', None]\n",
    ", ['h1_wbc_min', None]\n",
    ", ['h1_wbc_max', None]\n",
    ", ['h1_arterial_ph_min', None]\n",
    ", ['h1_arterial_ph_max', None]\n",
    ", ['h1_arterial_po2_min', None]\n",
    ", ['h1_arterial_po2_max', None]\n",
    ", ['h1_arterial_pco2_min', None]\n",
    ", ['h1_arterial_pco2_max', None]\n",
    ", ['h1_pao2fio2ratio_min', None]\n",
    ", ['h1_pao2fio2ratio_max', None]\n",
    "# === COMORBIDITIES === #\n",
    "#, [None, 'diabetes']\n",
    "#, [None, 'diabetes_type']\n",
    "#, [None, 'aids']\n",
    "#, [None, 'tuberculosis']\n",
    "#, [None, 'past_tb']\n",
    "#, [None, 'hepatitis_b']\n",
    "#, [None, 'other_chronic']\n",
    "#, [None, 'other_chronic_specify']\n",
    "#, [None, 'antidiabetic']\n",
    "#, [None, 'antidiabetic_specify']\n",
    "#, [None, 'stayhr']\n",
    "\n",
    "# === APACHE III VARIABLES === #\n",
    ", ['albumin_apache', None]\n",
    ", ['bilirubin_apache', None]\n",
    ", ['creatinine_apache', None]\n",
    ", ['glucose_apache', None]\n",
    ", ['hematocrit_apache', None]\n",
    ", ['heart_rate_apache', None]\n",
    ", ['map_apache', None]\n",
    ", ['sodium_apache', None]\n",
    "# aps iii oxygenation blood gas\n",
    ", ['fio2_apache', None]\n",
    ", ['paco2_apache', None]\n",
    ", ['pao2_apache', None]\n",
    "# aps iii acid-base components\n",
    ", ['ph_apache', None]\n",
    ", ['paco2_for_ph_apache', None]\n",
    ", ['resprate_apache', None]\n",
    ", ['temp_apache', None]\n",
    ", ['bun_apache', None]\n",
    ", ['urineoutput_apache', None]\n",
    ", ['wbc_apache', None]\n",
    ", ['gcs_eyes_apache', None]\n",
    ", ['gcs_motor_apache', None]\n",
    ", ['gcs_verbal_apache', None]\n",
    ", ['gcs_apache', 'gcs_lowest']\n",
    ", ['gcs_unable_apache', None]\n",
    ", ['arf_apache', None]\n",
    ", ['ventilated_apache', 'mechanical_first_24h']\n",
    "# === TREATMENTS === #\n",
    "#, [None, 'vasoactive_first_h']\n",
    "#, [None, 'antibiotic_drugs']\n",
    "# === OUTPUT OF SCORING SYSTEMS === #\n",
    "#, [None, 'a_score'] # probably apache ii\n",
    "#, [None, 'prob'] # probably apache ii\n",
    ", ['apsiii', None]\n",
    ", ['apache_3j_score', None]\n",
    ", ['apache_3j_hospital_death_prob', None]\n",
    ", ['apache_4a_icu_death_prob', None]\n",
    ", ['apache_4a_hospital_death_prob', None]\n",
    "])\n",
    "        \n",
    "# === OTHER UNUSED VARIABLES === #\n",
    "#, [None, 'apachecode']\n",
    "#, [None, 'diagnosis']\n",
    "#, [None, 'temp_onadm'],\n",
    "#, [None, 'map_onadm']\n",
    "#, [None, 'heart_rate_onadm']\n",
    "#, [None, 'resp_rate_onadm']\n",
    "#, [None, 'pao2_onadm']\n",
    "#, [None, 'ph_onadm'],\n",
    "#, [None, 'sodium_onadm'],\n",
    "#, [None, 'pottasium_onadm'],\n",
    "#, [None, 'creatinine_onadm'],\n",
    "#, [None, 'pcv_onadm']\n",
    "#, [None, 'wbc_onadm']\n",
    "#, [None, 'gcs_highest']\n",
    "#, [None, 'gcs_onadm']\n",
    "#, [None, 'hb_onadm'],\n",
    "#, [None, 'sys_bp_onadm'],\n",
    "#, [None, 'saturate_onadm'],\n",
    "#, [None, 'fio2_highest']\n",
    "#, [None, 'fio2_lowest']\n",
    "#, [None, 'fio2_onadm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdr = pd.read_csv('../hdr/header.csv',header=None,sep=',')[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: hospital_bed_size_numeric not found in field mapping for NICST data!\n",
      "WARNING: intubated_apache not found in field mapping for NICST data!\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for c in hdr:\n",
    "    # did not find a mapping for the given variable\n",
    "    if c not in field_map:\n",
    "        print('WARNING: {} not found in field mapping for NICST data!'.format(c))\n",
    "        df_new[c] = None\n",
    "    # there is a mapping, but it indicates that we don't have any data\n",
    "    elif field_map[c] is None:\n",
    "        # plug in missing data into final dataframe\n",
    "        #print('WARNING: {} not available in NICST data!'.format(c))\n",
    "        df_new[c] = None\n",
    "    # there is a mapping, and the anzics definition matches the GOSISS definition\n",
    "    elif type(field_map[c]) == str:\n",
    "        # check the mapping refers to a column available in data\n",
    "        if field_map[c].lower() in df.columns.values:\n",
    "            # data exists, copy it over\n",
    "            df_new[c] = df[field_map[c]]\n",
    "        else:\n",
    "            print('WARNING: {} equivalent not found in NICST data! (Looked for \"{}\".)'.format(c, field_map[c].lower()))\n",
    "    # there is a mapping, and it's a function (usually a dictionary)\n",
    "    else:\n",
    "        # call the mapping\n",
    "        df_new[c] = field_map[c](df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Output the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new.to_csv('nicst-gossis-data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
