{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from SQL, parse it appropriately\n",
    "\n",
    "This script loads the data from a MIMIC-III database and parses the data for concepts required for the GOSSIS project. The script outputs the `mimic-iii-gossis-data.csv` file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "# cursors need to be rolled back if they fail\n",
    "def execute_query_safely(sql, con):\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    # try to execute the query\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "    except:\n",
    "        # if an exception, rollback, rethrow the exception - finally closes the connection\n",
    "        cur.execute('rollback;')\n",
    "        raise\n",
    "    finally:\n",
    "        cur.close()\n",
    "    \n",
    "    return\n",
    "\n",
    "import getpass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to localhost on port 5432 ...\n",
      "Username: alistairewj\n",
      "Password: ········\n",
      "Connected to postgres 9.5.9!\n"
     ]
    }
   ],
   "source": [
    "# prompt user for username/password\n",
    "host='localhost'\n",
    "port=5432\n",
    "print('Connecting to {} on port {} ...'.format(host,port))\n",
    "sqluser = getpass.getuser()\n",
    "sqlpass = getpass.getpass(prompt='Username: {}\\nPassword: '.format(sqluser))\n",
    "\n",
    "con = psycopg2.connect(dbname='mimic', host=host, port=port, user=sqluser, password=sqlpass)\n",
    "\n",
    "\n",
    "print('Connected to postgres {}.{}.{}!'.format(int(con.server_version/10000),\n",
    "                                              (con.server_version - int(con.server_version/10000)*10000)/100,\n",
    "                                              (con.server_version - int(con.server_version/100)*100)))\n",
    "\n",
    "# default is to write to public and read from both public and mimiciii\n",
    "query_schema = \"set search_path to public,mimiciii;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create initial cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating table using sql/cohort.sql ... done.\n"
     ]
    }
   ],
   "source": [
    "# read in file/create base cohort\n",
    "f = 'sql/cohort.sql'\n",
    "with open(f, 'r') as fp:\n",
    "    query = ''.join(fp.readlines())\n",
    "\n",
    "# Execute the query\n",
    "print('Generating table using {} ...'.format(f),end=' ')\n",
    "execute_query_safely(query_schema + query, con)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort - initial size: 61509 ICU stays\n",
      "   1346 (2.19%) - exclusion_nodata\n",
      "  15053 (24.47%) - exclusion_readmission\n",
      "   7745 (12.59%) - exclusion_age\n",
      "   3650 (5.93%) - exclusion_shortstay\n",
      "      0 (0.00%) - exclusion_missing_outcome\n",
      "Final cohort size: 38139.0 ICU stays (62.01%).\n"
     ]
    }
   ],
   "source": [
    "# take a peek at the base cohort\n",
    "query = query_schema + \"\"\"select * from gossis_cohort\"\"\"\n",
    "co = pd.read_sql_query(query,con)\n",
    "\n",
    "# print out the exclusions\n",
    "print('Cohort - initial size: {} ICU stays'.format(co.shape[0]))\n",
    "idxRem = np.zeros(co.shape[0])\n",
    "for c in co.columns:\n",
    "    if c.startswith('exclusion_'):\n",
    "        print('  {:5g} ({:2.2f}%) - {}'.format(np.sum(co[c]),np.mean(co[c])*100.0, c))\n",
    "        idxRem[co[c].values==1] = 1\n",
    "        \n",
    "print('  {:5g} ({:2.2f}%) - exclusion_missing_outcome'.format(0, 0))\n",
    "print('Final cohort size: {} ICU stays ({:2.2f}%).'.format(co.shape[0] - np.sum(idxRem), (1-np.mean(idxRem))*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create necessary materialized views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing vitals-first-hour.sql ... done.\n",
      "Executing vitals-first-day.sql ... done.\n",
      "Executing urine-output-first-day.sql ... done.\n",
      "Executing labs.sql ... done.\n",
      "Executing labs-first-hour.sql ... done.\n",
      "Executing labs-first-day.sql ... done.\n",
      "Executing gcs-first-day.sql ... done.\n",
      "Executing demographics.sql ... done.\n",
      "Executing bg.sql ... done.\n",
      "Executing bg-first-hour.sql ... done.\n",
      "Executing bg-first-day.sql ... done.\n",
      "Executing apsiii.sql ... done.\n"
     ]
    }
   ],
   "source": [
    "# get a list of all SQL files in the subfolder\n",
    "query_path = './sql/'\n",
    "queries = [f for f in os.listdir(query_path) \n",
    "             # only keep the filename if it is actually a file (and not a directory)\n",
    "            if os.path.isfile(os.path.join(query_path,f))\n",
    "             # and only keep the filename if it is an SQL file\n",
    "            & f.endswith('.sql')\n",
    "            # and we do *not* want the cohort - it's generated above\n",
    "            & (f != 'cohort.sql')]\n",
    "\n",
    "queries = sorted(queries)[::-1]\n",
    "\n",
    "# make sure 'apsiii.sql' is the second to last query run\n",
    "if 'apsiii.sql' in queries:\n",
    "    queries.remove('apsiii.sql')\n",
    "    queries.append('apsiii.sql')\n",
    "\n",
    "# make sure 'data.sql' is not run\n",
    "if 'data.sql' in queries:\n",
    "    queries.remove('data.sql')\n",
    "\n",
    "# execute each SQL file to generate the materialized views\n",
    "for f in queries:\n",
    "    print('Executing {} ...'.format(f), end=' ')\n",
    "    \n",
    "    with open(os.path.join(query_path,f)) as fp:\n",
    "        query = ''.join(fp.readlines())\n",
    "        \n",
    "    execute_query_safely(query_schema + query, con)\n",
    "        \n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing data.sql ... done.\n"
     ]
    }
   ],
   "source": [
    "f = 'data.sql'\n",
    "print('Executing {} ...'.format(f), end=' ')\n",
    "\n",
    "with open(os.path.join(query_path,f)) as fp:\n",
    "    query = ''.join(fp.readlines())\n",
    "\n",
    "execute_query_safely(query_schema + query, con)\n",
    "\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Extract all covariates and outcome measures\n",
    "\n",
    "We now aggregate all the data from the various views into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 38139 patients and 197 features.\n"
     ]
    }
   ],
   "source": [
    "# Load in the query from file\n",
    "query = query_schema + \"\"\"\n",
    "--FINAL QUERY\n",
    "select\n",
    "  g.*\n",
    "from gossis g\n",
    "\"\"\"\n",
    "\n",
    "# Load the result of the query into a dataframe\n",
    "df = pd.read_sql_query(query, con)\n",
    "print('Loaded data for {} patients and {} features.'.format(df.shape[0],df.shape[1]-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdr = pd.read_csv('../hdr/header.csv',header=None,sep=',')[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the data into a consistent header which is used for all databases. Warn if data is not found in the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: icu_admit_type not found in MIMIC-III data!\n",
      "WARNING: arf_apache not found in MIMIC-III data!\n",
      "WARNING: diagnosis_apache not found in MIMIC-III data!\n",
      "WARNING: intubated_apache not found in MIMIC-III data!\n",
      "WARNING: apache_3j_hospital_death_prob not found in MIMIC-III data!\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for c in hdr:\n",
    "    # did not find a mapping for the given variable\n",
    "    if c not in df.columns:\n",
    "        print('WARNING: {} not found in MIMIC-III data!'.format(c))\n",
    "        df_new[c] = None\n",
    "    else:\n",
    "        # call the mapping\n",
    "        df_new[c] = df[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Output the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new.to_csv('mimic-iii-gossis-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
